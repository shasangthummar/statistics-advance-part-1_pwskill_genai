{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 1: What is a random variable in probability theory?**\n",
        "\n",
        "A **random variable** is a variable that takes on different numerical values based on the outcome of a random event or experiment.\n",
        "\n",
        "#### ‚úÖ More formally:\n",
        "A **random variable** maps outcomes of a sample space (the set of all possible outcomes of a random process) to real numbers.\n",
        "\n",
        "There are two main types:\n",
        "- **Discrete random variable**: Takes on a countable number of distinct values (e.g., number of heads in 3 coin flips).\n",
        "- **Continuous random variable**: Takes on any value in a continuous range (e.g., height, weight, temperature).\n",
        "\n",
        "#### üß† Why it matters:\n",
        "Random variables allow us to apply mathematical operations and statistical techniques to real-world phenomena that involve randomness.\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 2: What are the types of random variables?**\n",
        "\n",
        "There are **two major types**:\n",
        "\n",
        "#### 1. **Discrete Random Variables**\n",
        "- Takes **finite or countably infinite** values.\n",
        "- Example: Number of cars passing a signal, result of a dice roll.\n",
        "- Has a **probability mass function (PMF)**.\n",
        "\n",
        "#### 2. **Continuous Random Variables**\n",
        "- Takes **infinitely many values** over a continuous interval.\n",
        "- Example: Height of students, time taken to run a mile.\n",
        "- Described by a **probability density function (PDF)**.\n",
        "\n",
        "#### ‚öñÔ∏è Differences:\n",
        "| Feature              | Discrete                   | Continuous                 |\n",
        "|----------------------|----------------------------|-----------------------------|\n",
        "| Values               | Countable                  | Infinite/Uncountable        |\n",
        "| Probability Function | PMF                        | PDF                         |\n",
        "| Example              | Number of students         | Height of a student         |\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 3: What is the difference between discrete and continuous distributions?**\n",
        "\n",
        "A **distribution** describes how the values of a random variable are spread or distributed.\n",
        "\n",
        "#### üîπ Discrete Distribution:\n",
        "- Deals with discrete random variables.\n",
        "- Probability is assigned to **exact values**.\n",
        "- Example: Binomial, Poisson, Geometric.\n",
        "\n",
        "#### üî∏ Continuous Distribution:\n",
        "- Deals with continuous random variables.\n",
        "- Probability is described over an **interval**, not exact points.\n",
        "- Example: Normal, Uniform, Exponential.\n",
        "\n",
        "#### üìå Key Concept:\n",
        "- In discrete: \\( P(X = x) \\) makes sense.\n",
        "- In continuous: \\( P(X = x) = 0 \\); use \\( P(a < X < b) \\) instead.\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 4: What are probability distribution functions (PDF)?**\n",
        "\n",
        "A **Probability Distribution Function** describes how probabilities are distributed over the values of the random variable.\n",
        "\n",
        "#### üßæ Two main types:\n",
        "1. **Probability Mass Function (PMF)** ‚Äì for **discrete** variables.\n",
        "   - \\( P(X = x) \\)\n",
        "   - Example: Rolling a fair 6-sided die, \\( P(X = 3) = \\frac{1}{6} \\)\n",
        "\n",
        "2. **Probability Density Function (PDF)** ‚Äì for **continuous** variables.\n",
        "   - Used to calculate probabilities over intervals.\n",
        "   - \\( P(a \\leq X \\leq b) = \\int_a^b f(x)dx \\)\n",
        "   - The total area under the curve is 1.\n",
        "\n",
        "#### ‚ú≥Ô∏è Important:\n",
        "- PDFs give density, not probability directly.\n",
        "- PMFs give actual probability for specific values.\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 5: How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)?**\n",
        "\n",
        "A **Cumulative Distribution Function (CDF)** gives the **probability that a random variable is less than or equal to a certain value.**\n",
        "\n",
        "#### üìà CDF:\n",
        "- \\( F(x) = P(X \\leq x) \\)\n",
        "- Works for both discrete and continuous variables.\n",
        "- Always non-decreasing.\n",
        "- Range: [0, 1]\n",
        "\n",
        "#### ‚öñÔ∏è Difference from PDF:\n",
        "| Concept | PDF (Density)                  | CDF (Cumulative)                       |\n",
        "|--------|--------------------------------|----------------------------------------|\n",
        "| Meaning | Probability *density*         | Accumulated probability up to \\( x \\) |\n",
        "| Usage   | Used to derive probabilities  | Used to find cumulative probability   |\n",
        "| Formula (Cont.) | \\( f(x) = \\frac{d}{dx}F(x) \\) | \\( F(x) = \\int_{-\\infty}^x f(t)dt \\)    |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Maek91FUd-8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 6: What is a discrete uniform distribution?**\n",
        "\n",
        "A **discrete uniform distribution** is a probability distribution where **each possible outcome has an equal probability** of occurring.\n",
        "\n",
        "#### ‚úÖ Key Properties:\n",
        "- Finite set of outcomes.\n",
        "- All outcomes are **equally likely**.\n",
        "- Example: Rolling a fair 6-sided die ‚Üí outcomes = {1, 2, 3, 4, 5, 6}\n",
        "\n",
        "#### üìå Probability Formula:\n",
        "For a discrete uniform variable \\( X \\) with \\( n \\) outcomes:\n",
        "\n",
        "\\[\n",
        "P(X = x) = \\frac{1}{n}, \\quad \\text{for all } x\n",
        "\\]\n",
        "\n",
        "#### üîç Example:\n",
        "Let \\( X \\) be the outcome of rolling a fair die:\n",
        "\n",
        "\\[\n",
        "P(X=1) = P(X=2) = \\cdots = P(X=6) = \\frac{1}{6}\n",
        "\\]\n",
        "\n",
        "This makes the uniform distribution useful in modeling **purely random systems** like:\n",
        "- Coin flips\n",
        "- Lottery numbers\n",
        "- Random password digits\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 7: What are the key properties of a Bernoulli distribution?**\n",
        "\n",
        "The **Bernoulli distribution** models a **binary outcome**‚Äîa trial with exactly **two possible results**:\n",
        "- **Success** (often coded as 1)\n",
        "- **Failure** (coded as 0)\n",
        "\n",
        "#### ‚úÖ Properties:\n",
        "- Single trial.\n",
        "- Probability of success: \\( p \\)\n",
        "- Probability of failure: \\( 1 - p \\)\n",
        "\n",
        "#### üìå Probability Mass Function:\n",
        "\\[\n",
        "P(X = x) = p^x (1 - p)^{1 - x}, \\quad x \\in \\{0, 1\\}\n",
        "\\]\n",
        "\n",
        "#### üìä Mean and Variance:\n",
        "- Mean (Expected value): \\( E(X) = p \\)\n",
        "- Variance: \\( \\text{Var}(X) = p(1 - p) \\)\n",
        "\n",
        "#### üß† Real-world examples:\n",
        "- Tossing a coin (Heads = 1, Tails = 0)\n",
        "- Whether a customer buys (1) or doesn‚Äôt (0)\n",
        "- Whether a website visit leads to a signup\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 8: What is the binomial distribution, and how is it used in probability?**\n",
        "\n",
        "The **binomial distribution** models the number of **successes** in a fixed number \\( n \\) of **independent** Bernoulli trials, each with the **same probability of success** \\( p \\).\n",
        "\n",
        "#### ‚úÖ Use Cases:\n",
        "- Number of heads in 10 coin flips\n",
        "- Number of defective items in a batch\n",
        "- Number of correct answers on a multiple-choice test (guessing)\n",
        "\n",
        "#### üìå PMF Formula:\n",
        "\\[\n",
        "P(X = k) = \\binom{n}{k} p^k (1 - p)^{n - k}\n",
        "\\]\n",
        "Where:\n",
        "- \\( n \\) = number of trials\n",
        "- \\( k \\) = number of successes\n",
        "- \\( p \\) = probability of success\n",
        "\n",
        "#### üìä Mean and Variance:\n",
        "- Mean: \\( E(X) = np \\)\n",
        "- Variance: \\( \\text{Var}(X) = np(1 - p) \\)\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 9: What is the Poisson distribution and where is it applied?**\n",
        "\n",
        "The **Poisson distribution** models the number of **events occurring in a fixed interval** of time or space, **assuming**:\n",
        "- Events occur **independently**\n",
        "- At a **constant average rate** \\( \\lambda \\)\n",
        "- Two events cannot occur at exactly the same instant\n",
        "\n",
        "#### ‚úÖ Use Cases:\n",
        "- Number of emails received in an hour\n",
        "- Number of earthquakes in a year\n",
        "- Number of decay events per second from a radioactive source\n",
        "\n",
        "#### üìå PMF Formula:\n",
        "\\[\n",
        "P(X = k) = \\frac{e^{-\\lambda} \\lambda^k}{k!}, \\quad k = 0, 1, 2, \\ldots\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( \\lambda \\) = expected number of events (mean rate)\n",
        "\n",
        "#### üìä Mean and Variance:\n",
        "- Mean = \\( \\lambda \\)\n",
        "- Variance = \\( \\lambda \\)\n",
        "\n",
        "#### üîÅ Relationship:\n",
        "- Poisson is the **limiting case** of the Binomial distribution as \\( n \\to \\infty \\) and \\( p \\to 0 \\) while \\( np = \\lambda \\) stays constant.\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 10: What is a continuous uniform distribution?**\n",
        "\n",
        "A **continuous uniform distribution** is a probability distribution in which **all intervals of the same length** within a range are **equally probable**.\n",
        "\n",
        "#### ‚úÖ Properties:\n",
        "- Describes a **constant density** across an interval.\n",
        "- Every value in interval \\( [a, b] \\) is equally likely.\n",
        "\n",
        "#### üìå PDF Formula:\n",
        "\\[\n",
        "f(x) =\n",
        "\\begin{cases}\n",
        "\\frac{1}{b - a}, & a \\leq x \\leq b \\\\\n",
        "0, & \\text{otherwise}\n",
        "\\end{cases}\n",
        "\\]\n",
        "\n",
        "#### üìä Mean and Variance:\n",
        "- Mean: \\( \\frac{a + b}{2} \\)\n",
        "- Variance: \\( \\frac{(b - a)^2}{12} \\)\n",
        "\n",
        "#### üß† Examples:\n",
        "- Random number between 0 and 1\n",
        "- Time of day when an event randomly happens (between 2 PM and 4 PM)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2LIGe_hBeDN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 11: What are the characteristics of a normal distribution?**\n",
        "\n",
        "A **normal distribution** is a continuous probability distribution that is **bell-shaped** and **symmetric** about its **mean**.\n",
        "\n",
        "#### ‚úÖ Key Characteristics:\n",
        "- **Symmetry**: The curve is symmetrical around the mean \\( \\mu \\).\n",
        "- **Unimodal**: It has a single peak at the mean.\n",
        "- **Mean = Median = Mode**\n",
        "- **Asymptotic**: The tails approach the x-axis but never touch it.\n",
        "- **Defined by two parameters**: Mean \\( \\mu \\), and standard deviation \\( \\sigma \\)\n",
        "\n",
        "#### üìå Probability Density Function (PDF):\n",
        "\n",
        "\\[\n",
        "f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\, e^{ -\\frac{(x - \\mu)^2}{2\\sigma^2} }\n",
        "\\]\n",
        "\n",
        "#### üß† Why it‚Äôs important:\n",
        "- Many natural phenomena follow it (heights, test scores, measurement errors).\n",
        "- Foundation for statistical inference (like confidence intervals and hypothesis testing).\n",
        "\n",
        "#### üîç The **Empirical Rule** (68‚Äì95‚Äì99.7 rule):\n",
        "- 68% of data within 1 standard deviation of mean\n",
        "- 95% within 2 standard deviations\n",
        "- 99.7% within 3 standard deviations\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 12: What is the standard normal distribution, and why is it important?**\n",
        "\n",
        "The **standard normal distribution** is a special case of the normal distribution where:\n",
        "- \\( \\mu = 0 \\) (mean is 0)\n",
        "- \\( \\sigma = 1 \\) (standard deviation is 1)\n",
        "\n",
        "#### ‚úÖ Importance:\n",
        "- It allows us to use **Z-scores** to compare different normal distributions.\n",
        "- All normal distributions can be converted into standard normal using:\n",
        "\n",
        "\\[\n",
        "Z = \\frac{X - \\mu}{\\sigma}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( X \\) is the original value\n",
        "- \\( \\mu \\) is the mean\n",
        "- \\( \\sigma \\) is the standard deviation\n",
        "\n",
        "#### üß† Uses:\n",
        "- Standardized test scores (SAT, GRE)\n",
        "- Hypothesis testing\n",
        "- Confidence interval estimation\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 13: What is the Central Limit Theorem (CLT), and why is it critical in statistics?**\n",
        "\n",
        "The **Central Limit Theorem (CLT)** states that the **sampling distribution of the sample mean** will approximate a **normal distribution**, **regardless of the original population distribution**, provided the sample size is sufficiently large.\n",
        "\n",
        "#### ‚úÖ Key Conditions:\n",
        "- Samples must be **independent and identically distributed**.\n",
        "- Sample size \\( n \\geq 30 \\) is generally considered enough.\n",
        "- Finite variance and mean in the population.\n",
        "\n",
        "#### üìå Mathematically:\n",
        "If \\( X_1, X_2, ..., X_n \\) are i.i.d. with mean \\( \\mu \\) and variance \\( \\sigma^2 \\), then:\n",
        "\n",
        "\\[\n",
        "\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\n",
        "\\]\n",
        "\n",
        "#### üß† Why it‚Äôs important:\n",
        "- Justifies the **normal approximation** in hypothesis testing.\n",
        "- Enables us to construct **confidence intervals** even if population distribution is unknown.\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 14: How does the Central Limit Theorem relate to the normal distribution?**\n",
        "\n",
        "The CLT explains **why the normal distribution arises so frequently** in statistics. Even when the population itself is **not normally distributed**, the **distribution of the sample mean becomes approximately normal** as the sample size increases.\n",
        "\n",
        "#### üìå Practical Impact:\n",
        "- You can **use normal distribution tools (Z-scores, tables)** for inference about sample means even with non-normal data, **thanks to CLT**.\n",
        "- This bridges real-world, often non-normal data, with robust statistical techniques.\n",
        "\n",
        "#### üîç Example:\n",
        "Suppose you‚Äôre measuring weights of apples. If you take many random samples of 40 apples each and compute their means, those means will form a **bell-shaped curve** regardless of how skewed the individual weights are.\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 15: What is the application of Z statistics in hypothesis testing?**\n",
        "\n",
        "The **Z-statistic** (or Z-score) is used to determine how far a data point (or sample mean) is from the population mean in units of standard deviation.\n",
        "\n",
        "#### üìå Z-Score Formula:\n",
        "\n",
        "\\[\n",
        "Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( \\bar{X} \\) = sample mean\n",
        "- \\( \\mu \\) = population mean\n",
        "- \\( \\sigma \\) = population standard deviation\n",
        "- \\( n \\) = sample size\n",
        "\n",
        "#### ‚úÖ Applications in Hypothesis Testing:\n",
        "1. **One-sample Z-test**: Test whether a sample mean differs from a known population mean.\n",
        "2. **Two-sample Z-test**: Compare means from two independent samples.\n",
        "3. **Z-test for proportions**: Compare sample proportions.\n",
        "\n",
        "#### üß† Decision Rule:\n",
        "- If \\( |Z| > Z_{\\text{critical}} \\), **reject the null hypothesis**.\n",
        "- Based on chosen significance level (e.g., 0.05 ‚Üí \\( Z_{\\text{critical}} = \\pm1.96 \\))\n",
        "\n",
        "#### üîç Example:\n",
        "You claim the average height is 170 cm. Sample mean = 173, \\( \\sigma = 5 \\), \\( n = 25 \\):\n",
        "\n",
        "\\[\n",
        "Z = \\frac{173 - 170}{5 / \\sqrt{25}} = \\frac{3}{1} = 3\n",
        "\\]\n",
        "\n",
        "Since \\( Z = 3 > 1.96 \\), you reject the null hypothesis at the 5% level.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "T7NsALMTeUyc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 16: How do you calculate a Z-score, and what does it represent?**\n",
        "\n",
        "#### ‚úÖ **What is a Z-score?**\n",
        "A **Z-score** measures how many **standard deviations** a data point is **away from the mean** of a distribution.\n",
        "\n",
        "#### üìå **Formula for a single data point:**\n",
        "\\[\n",
        "Z = \\frac{X - \\mu}{\\sigma}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( X \\) = individual data point\n",
        "- \\( \\mu \\) = population mean\n",
        "- \\( \\sigma \\) = population standard deviation\n",
        "\n",
        "#### üìå **Formula for a sample mean:**\n",
        "\\[\n",
        "Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( \\bar{X} \\) = sample mean\n",
        "- \\( n \\) = sample size\n",
        "\n",
        "#### üß† **What does it represent?**\n",
        "- \\( Z = 0 \\): The value is exactly at the mean.\n",
        "- \\( Z = +1 \\): 1 standard deviation above the mean.\n",
        "- \\( Z = -2 \\): 2 standard deviations below the mean.\n",
        "- Helps compare data points across different distributions.\n",
        "\n",
        "#### üîç **Example:**\n",
        "Let‚Äôs say the average IQ is 100 with a standard deviation of 15. What is the Z-score for someone with an IQ of 130?\n",
        "\n",
        "\\[\n",
        "Z = \\frac{130 - 100}{15} = \\frac{30}{15} = 2\n",
        "\\]\n",
        "\n",
        "This person‚Äôs IQ is 2 standard deviations above the mean.\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 17: What are point estimates and interval estimates in statistics?**\n",
        "\n",
        "#### ‚úÖ **Point Estimate:**\n",
        "- A **single value** used as an estimate of a population parameter.\n",
        "- Most common point estimates:\n",
        "  - Sample mean \\( \\bar{X} \\) estimates population mean \\( \\mu \\)\n",
        "  - Sample proportion \\( \\hat{p} \\) estimates population proportion \\( p \\)\n",
        "\n",
        "#### üîç **Example:**\n",
        "You survey 100 people and find the average height is 167 cm.  \n",
        "‚Üí Point estimate of population height = 167 cm\n",
        "\n",
        "#### ‚úÖ **Interval Estimate:**\n",
        "- A **range of values** used to estimate a population parameter, with a specified level of confidence.\n",
        "- Example: Confidence interval.\n",
        "\n",
        "\\[\n",
        "\\text{CI} = \\bar{X} \\pm Z \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
        "\\]\n",
        "\n",
        "#### üß† **Why use interval estimates?**\n",
        "- Point estimates have no information about uncertainty.\n",
        "- Interval estimates give a **range** where the true parameter is **likely to lie**.\n",
        "\n",
        "#### üîç **Example:**\n",
        "Average height from sample = 167 cm  \n",
        "95% CI = [165.5, 168.5]  \n",
        "‚Üí We are 95% confident that the population mean lies in this range.\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 18: What is the significance of confidence intervals in statistical analysis?**\n",
        "\n",
        "A **confidence interval (CI)** provides a range of plausible values for a population parameter based on sample data.\n",
        "\n",
        "#### ‚úÖ **Why are CIs significant?**\n",
        "- Reflect **sampling uncertainty**.\n",
        "- Allow more **accurate inference** than point estimates alone.\n",
        "- Help in **hypothesis testing**.\n",
        "\n",
        "#### üìå **Structure of a CI:**\n",
        "\\[\n",
        "\\text{Estimate} \\pm \\text{Margin of Error}\n",
        "\\]\n",
        "\n",
        "Where Margin of Error = \\( Z \\cdot \\frac{\\sigma}{\\sqrt{n}} \\) (for known population std deviation)\n",
        "\n",
        "#### üß† **Common confidence levels:**\n",
        "- 90% (Z ‚âà 1.645)\n",
        "- 95% (Z ‚âà 1.96)\n",
        "- 99% (Z ‚âà 2.576)\n",
        "\n",
        "#### üîç **Interpretation:**\n",
        "A 95% CI means:  \n",
        "\"If we repeat this sampling process many times, 95% of the intervals we construct will contain the true population parameter.\"\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 19: What is the relationship between a Z-score and a confidence interval?**\n",
        "\n",
        "Z-scores and confidence intervals are **closely related** because Z-scores help define the **bounds** of a confidence interval.\n",
        "\n",
        "#### ‚úÖ **How?**\n",
        "- A **Z-score** determines **how many standard errors** to move away from the sample mean to form a CI.\n",
        "- For example, for 95% CI:\n",
        "  \\[\n",
        "  \\text{CI} = \\bar{X} \\pm 1.96 \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
        "  \\]\n",
        "\n",
        "#### üß† **Why this matters:**\n",
        "- **Z-scores** give the \"cutoff points\" for what is considered likely or unlikely.\n",
        "- The **larger the Z-score**, the **wider the interval** and the more confident you are.\n",
        "\n",
        "#### üîç **Example:**\n",
        "If sample mean = 170, \\( \\sigma = 10 \\), \\( n = 100 \\), then:\n",
        "\\[\n",
        "\\text{CI} = 170 \\pm 1.96 \\cdot \\frac{10}{\\sqrt{100}} = 170 \\pm 1.96\n",
        "\\Rightarrow [168.04, 171.96]\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 20: How are Z-scores used to compare different distributions?**\n",
        "\n",
        "Z-scores **standardize** values from **different distributions**, allowing direct comparison.\n",
        "\n",
        "#### ‚úÖ **Why compare using Z-scores?**\n",
        "Different datasets can have different:\n",
        "- Means\n",
        "- Variances\n",
        "- Units (cm vs inches, test scores, etc.)\n",
        "\n",
        "By converting to Z-scores, we bring all data to a **common scale**.\n",
        "\n",
        "#### üîç **Example:**\n",
        "- Student A scores 85 on a math test (mean = 80, std dev = 5)\n",
        "- Student B scores 75 on a physics test (mean = 70, std dev = 4)\n",
        "\n",
        "Z-scores:\n",
        "- A: \\( Z = \\frac{85 - 80}{5} = 1 \\)\n",
        "- B: \\( Z = \\frac{75 - 70}{4} = 1.25 \\)\n",
        "\n",
        "‚Üí Even though Student A had a higher raw score, Student B performed **better relative to peers**.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "sEs7RIQ4ekbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **QUESTION 21: What are the assumptions for applying the Central Limit Theorem (CLT)?**\n",
        "\n",
        "The **Central Limit Theorem (CLT)** states that, for a **large enough sample size**, the **sampling distribution of the sample mean** will be approximately **normally distributed**, even if the original population is not normal.\n",
        "\n",
        "#### ‚úÖ **CLT Assumptions:**\n",
        "\n",
        "1. **Random Sampling**  \n",
        "   The data must be collected using a **random sampling method**, ensuring independence between observations.\n",
        "\n",
        "2. **Independent Observations**  \n",
        "   Each observation should be independent of others. For instance, sampling one student should not influence another‚Äôs data.\n",
        "\n",
        "3. **Sample Size (n)**  \n",
        "   - For **non-normal populations**, a sample size of **n ‚â• 30** is usually sufficient.  \n",
        "   - For **highly skewed or bimodal** populations, even **larger samples** may be needed.\n",
        "   - If the population is already normal, CLT applies **regardless of sample size**.\n",
        "\n",
        "4. **Finite Standard Deviation**  \n",
        "   The population from which samples are drawn must have a **finite variance** (no infinite values).\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 22: What is the concept of expected value in a probability distribution?**\n",
        "\n",
        "#### ‚úÖ **Definition:**\n",
        "The **expected value** (also called the **mean** or **mathematical expectation**) of a random variable is the **long-run average** value of repetitions of the experiment it represents.\n",
        "\n",
        "#### üìå **Formula:**\n",
        "\n",
        "- For a **discrete** random variable:\n",
        "  \\[\n",
        "  E[X] = \\sum x_i \\cdot P(x_i)\n",
        "  \\]\n",
        "\n",
        "- For a **continuous** random variable:\n",
        "  \\[\n",
        "  E[X] = \\int_{-\\infty}^{\\infty} x \\cdot f(x)\\, dx\n",
        "  \\]\n",
        "\n",
        "Where:\n",
        "- \\( x_i \\): each possible value of X  \n",
        "- \\( P(x_i) \\): the probability of that value  \n",
        "- \\( f(x) \\): PDF (probability density function) of a continuous variable\n",
        "\n",
        "#### üîç **Example (Discrete):**\n",
        "Let a die be rolled. Expected value of the outcome:\n",
        "\n",
        "\\[\n",
        "E[X] = 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + \\ldots + 6 \\cdot \\frac{1}{6} = 3.5\n",
        "\\]\n",
        "\n",
        "‚Üí You *expect* the average value of a roll to be 3.5 in the long run.\n",
        "\n",
        "---\n",
        "\n",
        "### **QUESTION 23: How does a probability distribution relate to the expected outcome of a random variable?**\n",
        "\n",
        "#### ‚úÖ **Connection:**\n",
        "- A **probability distribution** gives the **likelihood of each outcome** of a random variable.\n",
        "- The **expected outcome** is the **weighted average** of all possible outcomes, using their probabilities as weights.\n",
        "\n",
        "#### üìå **Interpretation:**\n",
        "- The **probability distribution** tells you **what outcomes are possible** and **how likely** each one is.\n",
        "- The **expected value** condenses all of that into **one average number** ‚Äî what you \"expect\" over time.\n",
        "\n",
        "#### üîç **Example:**\n",
        "Consider a biased coin where:\n",
        "- \\( P(\\text{Heads}) = 0.7 \\), \\( P(\\text{Tails}) = 0.3 \\)\n",
        "- Let \\( X = 1 \\) for heads, \\( X = 0 \\) for tails\n",
        "\n",
        "Then:\n",
        "\\[\n",
        "E[X] = (1 \\cdot 0.7) + (0 \\cdot 0.3) = 0.7\n",
        "\\]\n",
        "\n",
        "‚Üí The expected number of heads per toss = 0.7 (on average, over many tosses).\n",
        "\n",
        "#### üß† Summary:\n",
        "The **expected value** is calculated using the **probabilities from the distribution**. Hence, a probability distribution directly determines what you expect a random variable to yield.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "p7uNZH57ezlP"
      }
    }
  ]
}